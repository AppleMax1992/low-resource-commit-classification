{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f82a8cc-7b02-48d7-a783-6e89bccff8b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T09:02:15.935706Z",
     "iopub.status.busy": "2025-01-11T09:02:15.934172Z",
     "iopub.status.idle": "2025-01-11T09:02:18.464836Z",
     "shell.execute_reply": "2025-01-11T09:02:18.464197Z",
     "shell.execute_reply.started": "2025-01-11T09:02:15.935651Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "root\n",
      "ensemble_commit\n",
      "/root/ensemble_commit\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import os\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "notebook_path = os.path.abspath('')\n",
    "import sys\n",
    "# Find the part of the path that contains 'commitFit'\n",
    "commit_fit_path = None\n",
    "for part in notebook_path.split(os.sep):\n",
    "    print(part)\n",
    "    if 'ensemble_commit' in part:\n",
    "        commit_fit_path = notebook_path.split(part)[0] + part\n",
    "        print(commit_fit_path)\n",
    "        break\n",
    "\n",
    "# import whatthepatch\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_curve,classification_report\n",
    "from tqdm import tqdm as std_tqdm\n",
    "from functools import partial\n",
    "tqdm = partial(std_tqdm, dynamic_ncols=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537e23dd-4090-40f0-8c1c-3ed2e96076cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "666cb7bc-ce61-42cb-b7fa-934b5e5d3580",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T09:02:18.466399Z",
     "iopub.status.busy": "2025-01-11T09:02:18.466099Z",
     "iopub.status.idle": "2025-01-11T09:02:21.168439Z",
     "shell.execute_reply": "2025-01-11T09:02:21.167654Z",
     "shell.execute_reply.started": "2025-01-11T09:02:18.466376Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1757/1193077617.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace({\"label\": label2id})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Merge pull request #46 from rufferson/saslx-tl...</td>\n",
       "      <td>diff --git a/lib/DJabberd.pm b/lib/DJabberd.pm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Fix leaks in kadmin server stubs [CVE-2015-863...</td>\n",
       "      <td>diff --git a/src/kadmin/server/server_stubs.c ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Validate authorization request on approval\\n\\n...</td>\n",
       "      <td>diff --git a/spring-security-oauth2/src/main/j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Release 2.72.4+171110</td>\n",
       "      <td>diff --git a/application/config/version.php b/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Fixing compiler warnings.</td>\n",
       "      <td>diff --git a/src/main.c b/src/main.c\\nindex 50...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10107</th>\n",
       "      <td>10107</td>\n",
       "      <td>0</td>\n",
       "      <td>les: remove useless protocol defines (#22115)\\...</td>\n",
       "      <td>diff --git a/les/benchmark.go b/les/benchmark....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10108</th>\n",
       "      <td>10108</td>\n",
       "      <td>1</td>\n",
       "      <td>Merge pull request #2067 from realm/tg-swift-l...</td>\n",
       "      <td>diff --git a/CHANGELOG.md b/CHANGELOG.md\\ninde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10109</th>\n",
       "      <td>10109</td>\n",
       "      <td>0</td>\n",
       "      <td>[fix] 新規アカウント作成ページの翻訳を修正</td>\n",
       "      <td>diff --git a/app/locales/ja_JP/LC_MESSAGES/mes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10110</th>\n",
       "      <td>10110</td>\n",
       "      <td>0</td>\n",
       "      <td>Merge branch 'hotfixes'</td>\n",
       "      <td>diff --git a/CHANGELOG.txt b/CHANGELOG.txt\\nin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10111</th>\n",
       "      <td>10111</td>\n",
       "      <td>1</td>\n",
       "      <td>HTTPCLIENT-1803: Improved handling of malforme...</td>\n",
       "      <td>diff --git a/httpclient/src/main/java/org/apac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10064 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  label                                            message  \\\n",
       "0               0      0  Merge pull request #46 from rufferson/saslx-tl...   \n",
       "1               1      1  Fix leaks in kadmin server stubs [CVE-2015-863...   \n",
       "2               2      1  Validate authorization request on approval\\n\\n...   \n",
       "3               3      1                              Release 2.72.4+171110   \n",
       "4               4      0                          Fixing compiler warnings.   \n",
       "...           ...    ...                                                ...   \n",
       "10107       10107      0  les: remove useless protocol defines (#22115)\\...   \n",
       "10108       10108      1  Merge pull request #2067 from realm/tg-swift-l...   \n",
       "10109       10109      0                           [fix] 新規アカウント作成ページの翻訳を修正   \n",
       "10110       10110      0                            Merge branch 'hotfixes'   \n",
       "10111       10111      1  HTTPCLIENT-1803: Improved handling of malforme...   \n",
       "\n",
       "                                                    diff  \n",
       "0      diff --git a/lib/DJabberd.pm b/lib/DJabberd.pm...  \n",
       "1      diff --git a/src/kadmin/server/server_stubs.c ...  \n",
       "2      diff --git a/spring-security-oauth2/src/main/j...  \n",
       "3      diff --git a/application/config/version.php b/...  \n",
       "4      diff --git a/src/main.c b/src/main.c\\nindex 50...  \n",
       "...                                                  ...  \n",
       "10107  diff --git a/les/benchmark.go b/les/benchmark....  \n",
       "10108  diff --git a/CHANGELOG.md b/CHANGELOG.md\\ninde...  \n",
       "10109  diff --git a/app/locales/ja_JP/LC_MESSAGES/mes...  \n",
       "10110  diff --git a/CHANGELOG.txt b/CHANGELOG.txt\\nin...  \n",
       "10111  diff --git a/httpclient/src/main/java/org/apac...  \n",
       "\n",
       "[10064 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'../datasets/dataset.csv', encoding='utf_8_sig')\n",
    "df.dropna(inplace=True)\n",
    "label2id={'negative':0,'positive':1}\n",
    "df = df.replace({\"label\": label2id})\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa751a3e-86ae-4f11-82ca-c173f5320a09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T09:02:21.169597Z",
     "iopub.status.busy": "2025-01-11T09:02:21.169401Z",
     "iopub.status.idle": "2025-01-11T09:02:21.179263Z",
     "shell.execute_reply": "2025-01-11T09:02:21.178529Z",
     "shell.execute_reply.started": "2025-01-11T09:02:21.169575Z"
    }
   },
   "outputs": [],
   "source": [
    "train, _ = train_test_split(df, train_size=0.35, random_state=42)\n",
    "train, test = train_test_split(train, test_size=0.3, random_state=42)\n",
    "test, val = train_test_split(test, train_size=0.5, random_state=42)\n",
    "\n",
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)\n",
    "val.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1f1e42a-ca2a-47b4-aeb0-536795d2a2f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T09:02:21.180322Z",
     "iopub.status.busy": "2025-01-11T09:02:21.180121Z",
     "iopub.status.idle": "2025-01-11T09:02:21.183776Z",
     "shell.execute_reply": "2025-01-11T09:02:21.182993Z",
     "shell.execute_reply.started": "2025-01-11T09:02:21.180295Z"
    }
   },
   "outputs": [],
   "source": [
    "# codebert_model.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1549be02-6f6b-41e5-bd04-d3e164061eec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T09:02:21.185837Z",
     "iopub.status.busy": "2025-01-11T09:02:21.185529Z",
     "iopub.status.idle": "2025-01-11T09:02:21.277051Z",
     "shell.execute_reply": "2025-01-11T09:02:21.276065Z",
     "shell.execute_reply.started": "2025-01-11T09:02:21.185815Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "\n",
    "# 构建自定义数据集\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, df, message_vocab, code_vocab, max_len):\n",
    "        self.messages = df[\"message\"].apply(lambda x: self.encode_text(x.split(), message_vocab, max_len)).tolist()\n",
    "        self.codes = df[\"diff\"].apply(lambda x: self.encode_text(x.split(), code_vocab, max_len)).tolist()\n",
    "        self.labels = df[\"label\"].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        messages = np.array(self.messages[idx], dtype=np.int64)\n",
    "        codes = np.array(self.codes[idx], dtype=np.int64)\n",
    "        label = int(self.labels[idx])  # 确保单个标量是整数类型\n",
    "        return messages, codes, label\n",
    "\n",
    "    @staticmethod\n",
    "    def encode_text(text, vocab, max_len):\n",
    "        encoded = [vocab[word] if word in vocab else 0 for word in text]\n",
    "        return encoded + [0] * (max_len - len(encoded))\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    messages, codes, labels = zip(*batch)\n",
    "    \n",
    "    # 确保 messages 和 codes 是二维张量，并填充\n",
    "    messages = pad_sequence([torch.tensor(msg, dtype=torch.long) for msg in messages], batch_first=True, padding_value=0)\n",
    "    codes = pad_sequence([torch.tensor(code, dtype=torch.long) for code in codes], batch_first=True, padding_value=0)\n",
    "    \n",
    "    # 确保 labels 是一维张量\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    return messages, codes, labels\n",
    "    \n",
    "# 使用 gensim 训练 Word2Vec 模型\n",
    "def train_word2vec(sentences, vector_size=100, window=5, min_count=1):\n",
    "    model = gensim.models.Word2Vec(sentences, vector_size=vector_size, window=window, min_count=min_count)\n",
    "    return model\n",
    "\n",
    "# 定义 LSTM + CNN 模型\n",
    "class LSTM_CNN_Model(nn.Module):\n",
    "    def __init__(self, message_vocab_size, code_vocab_size, embedding_dim, hidden_dim, lstm_layers, cnn_out_channels, num_classes, \n",
    "                 message_embedding_matrix=None, code_embedding_matrix=None):\n",
    "        super(LSTM_CNN_Model, self).__init__()\n",
    "        \n",
    "        # Embedding Layers for message and code\n",
    "        self.message_embedding = nn.Embedding(message_vocab_size, embedding_dim)\n",
    "        self.code_embedding = nn.Embedding(code_vocab_size, embedding_dim)\n",
    "        \n",
    "        if message_embedding_matrix is not None:\n",
    "            self.message_embedding.weight = nn.Parameter(torch.tensor(message_embedding_matrix, dtype=torch.float32))\n",
    "            self.message_embedding.weight.requires_grad = False\n",
    "        \n",
    "        if code_embedding_matrix is not None:\n",
    "            self.code_embedding.weight = nn.Parameter(torch.tensor(code_embedding_matrix, dtype=torch.float32))\n",
    "            self.code_embedding.weight.requires_grad = False\n",
    "        \n",
    "        # LSTM Layers\n",
    "        self.message_lstm = nn.LSTM(embedding_dim, hidden_dim, lstm_layers, batch_first=True, bidirectional=True)\n",
    "        self.code_lstm = nn.LSTM(embedding_dim, hidden_dim, lstm_layers, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        # CNN Layers\n",
    "        self.message_conv1d = nn.Conv1d(in_channels=hidden_dim * 2, out_channels=cnn_out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.code_conv1d = nn.Conv1d(in_channels=hidden_dim * 2, out_channels=cnn_out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Fully Connected Layer\n",
    "        self.fc = nn.Linear(cnn_out_channels * 2, num_classes)\n",
    "\n",
    "    def forward(self, message, code):\n",
    "        # Process message\n",
    "        message_embed = self.message_embedding(message)\n",
    "        message_lstm_out, _ = self.message_lstm(message_embed)\n",
    "        message_lstm_out = message_lstm_out.permute(0, 2, 1)  # Change to (batch, channels, seq_len)\n",
    "        message_features = torch.relu(self.message_conv1d(message_lstm_out))\n",
    "        message_features = torch.mean(message_features, dim=2)  # Global Average Pooling\n",
    "        \n",
    "        # Process code\n",
    "        code_embed = self.code_embedding(code)\n",
    "        code_lstm_out, _ = self.code_lstm(code_embed)\n",
    "        code_lstm_out = code_lstm_out.permute(0, 2, 1)  # Change to (batch, channels, seq_len)\n",
    "        code_features = torch.relu(self.code_conv1d(code_lstm_out))\n",
    "        code_features = torch.mean(code_features, dim=2)  # Global Average Pooling\n",
    "        \n",
    "        # Combine features\n",
    "        combined_features = torch.cat([message_features, code_features], dim=1)\n",
    "        output = self.fc(combined_features)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3ac72c0-bc7a-4e1c-88e2-54bcd03aeaa0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T09:02:21.278226Z",
     "iopub.status.busy": "2025-01-11T09:02:21.278026Z",
     "iopub.status.idle": "2025-01-11T09:02:21.287770Z",
     "shell.execute_reply": "2025-01-11T09:02:21.287066Z",
     "shell.execute_reply.started": "2025-01-11T09:02:21.278204Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>897</td>\n",
       "      <td>897</td>\n",
       "      <td>1</td>\n",
       "      <td>https://github.com/ImageMagick/ImageMagick/iss...</td>\n",
       "      <td>diff --git a/coders/png.c b/coders/png.c\\ninde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2072</td>\n",
       "      <td>2072</td>\n",
       "      <td>0</td>\n",
       "      <td>allocator_thread: rework message sending struc...</td>\n",
       "      <td>diff --git a/src/allocator_thread.c b/src/allo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8489</td>\n",
       "      <td>8489</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>diff --git a/coders/mpc.c b/coders/mpc.c\\ninde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1692</td>\n",
       "      <td>1692</td>\n",
       "      <td>0</td>\n",
       "      <td>Fix phpcs</td>\n",
       "      <td>diff --git a/src/Core/Configuration.php b/src/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7905</td>\n",
       "      <td>7905</td>\n",
       "      <td>0</td>\n",
       "      <td>Merge pull request #6467 from BrickOzp/attach2...</td>\n",
       "      <td>diff --git a/Themes/default/Display.template.p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2460</th>\n",
       "      <td>477</td>\n",
       "      <td>477</td>\n",
       "      <td>0</td>\n",
       "      <td>handles FNC1</td>\n",
       "      <td>diff --git a/lib/barby/barcode/code_128.rb b/l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2461</th>\n",
       "      <td>7035</td>\n",
       "      <td>7035</td>\n",
       "      <td>0</td>\n",
       "      <td>Bump tox from 3.20.1 to 3.21.3\\n\\nBumps [tox](...</td>\n",
       "      <td>diff --git a/requirements/dev.txt b/requiremen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2462</th>\n",
       "      <td>3539</td>\n",
       "      <td>3539</td>\n",
       "      <td>1</td>\n",
       "      <td>Strengthen sanitization, fixes #817</td>\n",
       "      <td>diff --git a/geo-mashup-db.php b/geo-mashup-db...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2463</th>\n",
       "      <td>5333</td>\n",
       "      <td>5333</td>\n",
       "      <td>0</td>\n",
       "      <td>modify short open tag &lt;? to &lt;?php\\n\\nThe short...</td>\n",
       "      <td>diff --git a/cookieviz/settings.inc b/cookievi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2464</th>\n",
       "      <td>2960</td>\n",
       "      <td>2960</td>\n",
       "      <td>0</td>\n",
       "      <td>Fix reference to versioned libcomps.so</td>\n",
       "      <td>diff --git a/libcomps/src/python/docs/doc-sour...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2465 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  Unnamed: 0  label  \\\n",
       "0       897         897      1   \n",
       "1      2072        2072      0   \n",
       "2      8489        8489      1   \n",
       "3      1692        1692      0   \n",
       "4      7905        7905      0   \n",
       "...     ...         ...    ...   \n",
       "2460    477         477      0   \n",
       "2461   7035        7035      0   \n",
       "2462   3539        3539      1   \n",
       "2463   5333        5333      0   \n",
       "2464   2960        2960      0   \n",
       "\n",
       "                                                message  \\\n",
       "0     https://github.com/ImageMagick/ImageMagick/iss...   \n",
       "1     allocator_thread: rework message sending struc...   \n",
       "2                                                   ...   \n",
       "3                                             Fix phpcs   \n",
       "4     Merge pull request #6467 from BrickOzp/attach2...   \n",
       "...                                                 ...   \n",
       "2460                                       handles FNC1   \n",
       "2461  Bump tox from 3.20.1 to 3.21.3\\n\\nBumps [tox](...   \n",
       "2462                Strengthen sanitization, fixes #817   \n",
       "2463  modify short open tag <? to <?php\\n\\nThe short...   \n",
       "2464             Fix reference to versioned libcomps.so   \n",
       "\n",
       "                                                   diff  \n",
       "0     diff --git a/coders/png.c b/coders/png.c\\ninde...  \n",
       "1     diff --git a/src/allocator_thread.c b/src/allo...  \n",
       "2     diff --git a/coders/mpc.c b/coders/mpc.c\\ninde...  \n",
       "3     diff --git a/src/Core/Configuration.php b/src/...  \n",
       "4     diff --git a/Themes/default/Display.template.p...  \n",
       "...                                                 ...  \n",
       "2460  diff --git a/lib/barby/barcode/code_128.rb b/l...  \n",
       "2461  diff --git a/requirements/dev.txt b/requiremen...  \n",
       "2462  diff --git a/geo-mashup-db.php b/geo-mashup-db...  \n",
       "2463  diff --git a/cookieviz/settings.inc b/cookievi...  \n",
       "2464  diff --git a/libcomps/src/python/docs/doc-sour...  \n",
       "\n",
       "[2465 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e01924f-b8a3-4282-acf6-6d38aee2620c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T09:02:21.288919Z",
     "iopub.status.busy": "2025-01-11T09:02:21.288649Z",
     "iopub.status.idle": "2025-01-11T09:02:45.453661Z",
     "shell.execute_reply": "2025-01-11T09:02:45.452634Z",
     "shell.execute_reply.started": "2025-01-11T09:02:21.288898Z"
    }
   },
   "outputs": [],
   "source": [
    "# 分别训练 Word2Vec 模型\n",
    "message_sentences = [msg.split() for msg in train[\"message\"]]\n",
    "code_sentences = [code.split() for code in train[\"diff\"]]\n",
    "message_word2vec = train_word2vec(message_sentences, vector_size=100)\n",
    "code_word2vec = train_word2vec(code_sentences, vector_size=100)\n",
    "\n",
    "# 构建词汇表\n",
    "message_vocab = {word: idx for idx, word in enumerate(message_word2vec.wv.index_to_key)}\n",
    "code_vocab = {word: idx for idx, word in enumerate(code_word2vec.wv.index_to_key)}\n",
    "\n",
    "# 构建嵌入矩阵\n",
    "message_embedding_matrix = np.zeros((len(message_vocab), 100))\n",
    "for word, idx in message_vocab.items():\n",
    "    message_embedding_matrix[idx] = message_word2vec.wv[word]\n",
    "\n",
    "code_embedding_matrix = np.zeros((len(code_vocab), 100))\n",
    "for word, idx in code_vocab.items():\n",
    "    code_embedding_matrix[idx] = code_word2vec.wv[word]\n",
    "\n",
    "# 数据处理\n",
    "max_len = 10\n",
    "train_dataset = TextDataset(train, message_vocab, code_vocab, max_len)\n",
    "# 创建 DataLoader 时指定 collate_fn\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ed3c4b6-0928-41ca-9284-04007afa5d06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T09:02:45.454821Z",
     "iopub.status.busy": "2025-01-11T09:02:45.454624Z",
     "iopub.status.idle": "2025-01-11T09:02:45.458290Z",
     "shell.execute_reply": "2025-01-11T09:02:45.457499Z",
     "shell.execute_reply.started": "2025-01-11T09:02:45.454800Z"
    }
   },
   "outputs": [],
   "source": [
    "# device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92009384-7770-4b2a-97b2-c0b4d209a0a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T09:02:45.459672Z",
     "iopub.status.busy": "2025-01-11T09:02:45.459106Z",
     "iopub.status.idle": "2025-01-11T09:02:45.789566Z",
     "shell.execute_reply": "2025-01-11T09:02:45.788717Z",
     "shell.execute_reply.started": "2025-01-11T09:02:45.459649Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dataset = TextDataset(test, message_vocab, code_vocab, max_len)\n",
    "# 创建 DataLoader 时指定 collate_fn\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9fa75e6-a2f6-455a-b588-5756a3963c31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T09:02:45.790924Z",
     "iopub.status.busy": "2025-01-11T09:02:45.790703Z",
     "iopub.status.idle": "2025-01-11T09:02:45.803891Z",
     "shell.execute_reply": "2025-01-11T09:02:45.803133Z",
     "shell.execute_reply.started": "2025-01-11T09:02:45.790902Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate(model, data_loader, criterion):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test dataset, computing loss, accuracy, precision, recall, and F1 score.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model to evaluate.\n",
    "        data_loader: DataLoader for the test dataset.\n",
    "        criterion: Loss function to evaluate the model's performance.\n",
    "        device: Device to run the evaluation (e.g., \"cpu\" or \"cuda\").\n",
    "    \n",
    "    Returns:\n",
    "        avg_loss: Average loss on the test dataset.\n",
    "        accuracy: Accuracy of the model on the test dataset.\n",
    "        precision: Precision score for the test dataset.\n",
    "        recall: Recall score for the test dataset.\n",
    "        f1: F1 score for the test dataset.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "        for messages, codes, labels in data_loader:\n",
    "            # Move data to the specified device\n",
    "            messages, codes, labels = torch.tensor(messages), torch.tensor(codes), torch.tensor(labels)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(messages, codes)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Update loss\n",
    "            total_loss += loss.item() * labels.size(0)  # Multiply by batch size\n",
    "            \n",
    "            # Compute predictions\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "            \n",
    "            # Collect predictions and true labels for metrics\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    # Compute average loss and accuracy\n",
    "    avg_loss = total_loss / total_samples\n",
    "    accuracy = total_correct / total_samples\n",
    "    \n",
    "    # Compute precision, recall, and F1 score\n",
    "    precision = precision_score(all_labels, all_preds, average=\"weighted\", zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average=\"weighted\", zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"weighted\", zero_division=0)\n",
    "    print(f'Validation Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1-Score: {f1}')\n",
    "    return all_labels, all_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a4c6ca0-8720-4fa3-b4d2-b6a70c5c5351",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T09:02:45.805228Z",
     "iopub.status.busy": "2025-01-11T09:02:45.804925Z",
     "iopub.status.idle": "2025-01-11T09:02:45.923292Z",
     "shell.execute_reply": "2025-01-11T09:02:45.922453Z",
     "shell.execute_reply.started": "2025-01-11T09:02:45.805205Z"
    }
   },
   "outputs": [],
   "source": [
    "model  = torch.load('PatchRNN_entire_bert_model_900repo.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d586669f-de71-49f1-b4e1-83f1659ba124",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T09:02:45.924449Z",
     "iopub.status.busy": "2025-01-11T09:02:45.924253Z",
     "iopub.status.idle": "2025-01-11T09:02:46.406965Z",
     "shell.execute_reply": "2025-01-11T09:02:46.405960Z",
     "shell.execute_reply.started": "2025-01-11T09:02:45.924427Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "030afb11-d884-4cea-ac5f-b7c8247909ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T09:02:46.408143Z",
     "iopub.status.busy": "2025-01-11T09:02:46.407944Z",
     "iopub.status.idle": "2025-01-11T09:03:29.144649Z",
     "shell.execute_reply": "2025-01-11T09:03:29.143797Z",
     "shell.execute_reply.started": "2025-01-11T09:02:46.408122Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1757/282295445.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  messages, codes, labels = torch.tensor(messages), torch.tensor(codes), torch.tensor(labels)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.615530303030303\n",
      "Precision: 0.6861915059144269\n",
      "Recall: 0.615530303030303\n",
      "F1-Score: 0.6195732204395415\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "all_labels,all_preds  = evaluate(model, test_loader, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e44b70c-68c0-4df1-b707-8ae144a5a312",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T09:03:29.147140Z",
     "iopub.status.busy": "2025-01-11T09:03:29.146940Z",
     "iopub.status.idle": "2025-01-11T09:03:29.157830Z",
     "shell.execute_reply": "2025-01-11T09:03:29.157067Z",
     "shell.execute_reply.started": "2025-01-11T09:03:29.147118Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8028    0.5224    0.6329       335\n",
      "           1     0.4839    0.7772    0.5964       193\n",
      "\n",
      "    accuracy                         0.6155       528\n",
      "   macro avg     0.6433    0.6498    0.6147       528\n",
      "weighted avg     0.6862    0.6155    0.6196       528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(all_labels,all_preds,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf19d667-f13b-4286-a1aa-6dbef58828ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T09:03:29.158826Z",
     "iopub.status.busy": "2025-01-11T09:03:29.158637Z",
     "iopub.status.idle": "2025-01-11T09:03:30.222318Z",
     "shell.execute_reply": "2025-01-11T09:03:30.220995Z",
     "shell.execute_reply.started": "2025-01-11T09:03:29.158805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在线模型训练完毕\n"
     ]
    }
   ],
   "source": [
    "#发送多种类型的邮件\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "import smtplib\n",
    "\n",
    "from email.mime.text import MIMEText\n",
    "msg_from = '915803745@qq.com'  # 发送方邮箱\n",
    "passwd = 'vcuosuurrgkfbdai'   #就是上面的授权码\n",
    " \n",
    "# to= ['g.zhang@gotion.com', 'j.tong@gotion.com'] #接受方邮箱\n",
    "to= ['j.tong@gotion.com'] #接受方邮箱\n",
    "#设置邮件内容\n",
    "#MIMEMultipart类可以放任何内容\n",
    "msg = MIMEMultipart()\n",
    "conntent=\"在线模型训练完毕\"\n",
    "#把内容加进去\n",
    "msg.attach(MIMEText(conntent,'plain','utf-8'))\n",
    " \n",
    "#设置邮件主题\n",
    "msg['Subject']=\"在线模型训练完毕\"\n",
    " \n",
    "#发送方信息\n",
    "msg['From']=msg_from\n",
    " \n",
    "#开始发送\n",
    " \n",
    "#通过SSL方式发送，服务器地址和端口\n",
    "s = smtplib.SMTP_SSL(\"smtp.qq.com\", 465)\n",
    "# 登录邮箱\n",
    "s.login(msg_from, passwd)\n",
    "#开始发送\n",
    "s.sendmail(msg_from,to,msg.as_string())\n",
    "print(\"在线模型训练完毕\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0040dfb2-eff0-4087-b618-a82f286940a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
